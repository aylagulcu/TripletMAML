{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921575ea",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1719ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a17743b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.4531e-01,  1.1717e-03],\n",
      "        [-1.3052e+00, -1.1816e+00]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed94569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9361e-01, 1.3729e-06],\n",
      "        [1.7035e+00, 1.3961e+00]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c17555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f2808fd93d0>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e894d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9983, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba36514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199bc42",
   "metadata": {},
   "source": [
    "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba23271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.7266e-01,  5.8586e-04],\n",
      "        [-6.5258e-01, -5.9078e-01]])\n",
      "tensor([[ 4.7266e-01,  5.8586e-04],\n",
      "        [-6.5258e-01, -5.9078e-01]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07166b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982856512069702"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e666363",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3189304565.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_16234/3189304565.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    net2.load_state_dict(net.state_dict())y.grad\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2 = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2.load_state_dict(net.state_dict())y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2b593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_grads= torch.autograd.grad(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50639a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2500, 0.2500],\n",
       "         [0.2500, 0.2500]]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e879900",
   "metadata": {},
   "source": [
    "### Copying module parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e022a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0500, 0.0600, 0.0100, 0.0400, 0.2000, 0.0570, 0.0840, 0.1450, 0.0140,\n",
      "        0.0220])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x= np.array([0.05, 0.06, 0.01, 0.04, 0.2, 0.057, 0.084, 0.145, 0.014, 0.022], dtype=np.float32)\n",
    "y= np.array([1], dtype=np.float32)\n",
    "x=torch.as_tensor(x)\n",
    "y=torch.as_tensor(y)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce128af4",
   "metadata": {},
   "source": [
    "### Example for clonning a module parameters using load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ee411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2 = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2.load_state_dict(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb26cf",
   "metadata": {},
   "source": [
    "### Example for clonning a module parameters using torch.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b74d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2 = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2[0].weight= torch.nn.Parameter(net[0].weight.clone())\n",
    "net2[2].weight= torch.nn.Parameter(net[2].weight.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27628222",
   "metadata": {},
   "source": [
    "### Example for clonning a module parameters using deepcopy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "net = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2 = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb58f7",
   "metadata": {},
   "source": [
    "### Example for clonning a module parameters using detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a91ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(10, 4, bias=False), nn.ReLU(), nn.Linear(4, 1, bias=False), nn.Sigmoid())\n",
    "net2[0].weight= torch.nn.Parameter(net[0].weight.detach().clone())\n",
    "net2[2].weight= torch.nn.Parameter(net[2].weight.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310c333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2419a19",
   "metadata": {},
   "source": [
    "# Now test each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ca14f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=4, bias=False)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (3): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=4, bias=False)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=False)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2497e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net parameters \n",
      " [Parameter containing:\n",
      "tensor([[-0.0969, -0.0174, -0.0342,  0.1916,  0.0039,  0.1663, -0.2375, -0.1561,\n",
      "          0.0982, -0.1324],\n",
      "        [ 0.1330,  0.1270, -0.0508, -0.2828, -0.1075, -0.0015,  0.1396,  0.2473,\n",
      "         -0.3151,  0.1716],\n",
      "        [-0.2688, -0.3004,  0.0702, -0.2984, -0.2828,  0.0428,  0.0161, -0.2365,\n",
      "          0.2222, -0.2657],\n",
      "        [-0.2590,  0.1048,  0.1980,  0.2172,  0.0037, -0.0745, -0.2623,  0.0855,\n",
      "         -0.0913,  0.0862]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2993,  0.0315,  0.3062, -0.2269]], requires_grad=True)]\n",
      "Net2 parameters \n",
      " [Parameter containing:\n",
      "tensor([[-0.0969, -0.0174, -0.0342,  0.1916,  0.0039,  0.1663, -0.2375, -0.1561,\n",
      "          0.0982, -0.1324],\n",
      "        [ 0.1330,  0.1270, -0.0508, -0.2828, -0.1075, -0.0015,  0.1396,  0.2473,\n",
      "         -0.3151,  0.1716],\n",
      "        [-0.2688, -0.3004,  0.0702, -0.2984, -0.2828,  0.0428,  0.0161, -0.2365,\n",
      "          0.2222, -0.2657],\n",
      "        [-0.2590,  0.1048,  0.1980,  0.2172,  0.0037, -0.0745, -0.2623,  0.0855,\n",
      "         -0.0913,  0.0862]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.2993,  0.0315,  0.3062, -0.2269]], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print('Net parameters \\n', list(net.parameters()))\n",
    "print('Net2 parameters \\n', list(net2.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f774d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net first linear layer weights \n",
      " OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "print('Net first linear layer weights \\n', net._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689e26e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net first linear layer weights \n",
      " Linear(in_features=10, out_features=4, bias=False)\n",
      "Net2 first linear layer weights \n",
      " Parameter containing:\n",
      "tensor([[-0.0969, -0.0174, -0.0342,  0.1916,  0.0039,  0.1663, -0.2375, -0.1561,\n",
      "          0.0982, -0.1324],\n",
      "        [ 0.1330,  0.1270, -0.0508, -0.2828, -0.1075, -0.0015,  0.1396,  0.2473,\n",
      "         -0.3151,  0.1716],\n",
      "        [-0.2688, -0.3004,  0.0702, -0.2984, -0.2828,  0.0428,  0.0161, -0.2365,\n",
      "          0.2222, -0.2657],\n",
      "        [-0.2590,  0.1048,  0.1980,  0.2172,  0.0037, -0.0745, -0.2623,  0.0855,\n",
      "         -0.0913,  0.0862]], requires_grad=True)\n",
      "\n",
      "\n",
      "Net second linear layer weights \n",
      " Parameter containing:\n",
      "tensor([[ 0.2993,  0.0315,  0.3062, -0.2269]], requires_grad=True)\n",
      "Net2 second linear layer weights \n",
      " Parameter containing:\n",
      "tensor([[ 0.2993,  0.0315,  0.3062, -0.2269]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Net first linear layer weights \\n', net[0].weight)\n",
    "print('Net2 first linear layer weights \\n',net2[0].weight)\n",
    "print('\\n')\n",
    "print('Net second linear layer weights \\n', net[2].weight)\n",
    "print('Net2 second linear layer weights \\n', net2[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Net first linear layer weights gradients \\n', net[0].weight.grad)\n",
    "print('Net2 first linear layer weights gradients \\n',net2[0].weight.grad)\n",
    "print('\\n')\n",
    "print('Net second linear layer weights gradients \\n', net[2].weight.grad)\n",
    "print('Net2 second linear layer weights gradients \\n', net2[2].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddef2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One gradient update step is called on Net2:\n",
    "loss= nn.BCEWithLogitsLoss()\n",
    "opt= torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = loss(net(x), y)\n",
    "error.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58352c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Net first linear layer weights \\n', net[0].weight)\n",
    "print('Net2 first linear layer weights \\n',net2[0].weight)\n",
    "print('\\n')\n",
    "print('Net second linear layer weights \\n', net[2].weight)\n",
    "print('Net2 second linear layer weights \\n', net2[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a95033",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Net first linear layer weights gradients \\n', net[0].weight.grad)\n",
    "print('Net2 first linear layer weights gradients \\n',net2[0].weight.grad)\n",
    "print('\\n')\n",
    "print('Net second linear layer weights gradients \\n', net[2].weight.grad)\n",
    "print('Net2 second linear layer weights gradients \\n', net2[2].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f0236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('meta1': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd04c746eb95852000f7e61dfc0add9c8194ac091bc77cc920f3c9e782bc8f4568c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
